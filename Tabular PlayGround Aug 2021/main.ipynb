{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "train_data = pd.read_csv(\"train.csv\",index_col = 'id')\n",
    "test_data = pd.read_csv(\"test.csv\",index_col = 'id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(train_data.mean())\n",
    "test_data = test_data.fillna(train_data.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "Y_train = train_data['loss'].copy()\n",
    "X_train = train_data.copy().drop('loss', axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "                  f0             f1             f2             f3  \\\ncount  250000.000000  250000.000000  250000.000000  250000.000000   \nmean        0.511213      51.378476       0.107155       0.050010   \nstd         0.307884      42.396636       1.322200       0.792368   \nmin        -0.069273     -17.000000      -7.895580      -1.475560   \n25%         0.251287      18.000000      -0.611172      -0.719418   \n50%         0.514962      41.000000       0.253815       0.004099   \n75%         0.777323      75.000000       0.759249       0.765456   \nmax         1.072070     273.000000       9.768590       1.680190   \n\n                  f4             f5             f6             f7  \\\ncount  250000.000000  250000.000000  250000.000000  250000.000000   \nmean     3595.133426       8.205953     164.508753       0.375533   \nstd      6072.401061       5.475723     183.335563       0.813597   \nmin     -7589.280000      -3.291050     -40.967200      -4.143080   \n25%       163.864750       4.110127      27.894900      -0.026245   \n50%       943.000500       7.472445      91.005250       0.619862   \n75%      4115.355000      11.030950     240.843750       0.933855   \nmax     37847.500000      35.078000     947.143000       4.010380   \n\n                  f8             f9  ...            f90            f91  \\\ncount  250000.000000  250000.000000  ...  250000.000000  250000.000000   \nmean       16.669745       1.190382  ...       0.581002    4856.812768   \nstd        99.758709       0.099700  ...       0.445022    8501.609009   \nmin      -502.813000       0.934037  ...      -0.379189  -12695.700000   \n25%       -17.392025       1.132640  ...       0.280511      73.203100   \n50%         8.714945       1.170370  ...       0.480568    1060.025000   \n75%        55.407625       1.218880  ...       0.766532    5572.982500   \nmax       465.956000       1.712450  ...       3.422660   54334.600000   \n\n                 f92            f93            f94            f95  \\\ncount  250000.000000  250000.000000  250000.000000  250000.000000   \nmean       22.579100       2.030554       0.079692       1.555097   \nstd        14.849390       0.900211       0.587780       9.253785   \nmin        -4.059170       0.057800      -1.998800     -24.686300   \n25%        11.525450       1.471650      -0.408975      -4.004925   \n50%        19.993200       1.660830       0.215710       0.759942   \n75%        32.271625       2.320085       0.503134       6.202502   \nmax        79.912400       5.403020       1.944190      42.890400   \n\n                 f96            f97            f98            f99  \ncount  250000.000000  250000.000000  250000.000000  250000.000000  \nmean        2.417556       0.537484       1.576900       8.048805  \nstd         0.892563       0.226589       0.646306       5.647368  \nmin        -1.131980       0.005249      -0.646967      -0.842397  \n25%         1.906718       0.359646       1.215810       3.732800  \n50%         2.340430       0.531347       1.451285       7.182205  \n75%         2.910020       0.709807       1.901633      10.998550  \nmax         5.576040       1.105400       4.492620      34.019200  \n\n[8 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f0</th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>f6</th>\n      <th>f7</th>\n      <th>f8</th>\n      <th>f9</th>\n      <th>...</th>\n      <th>f90</th>\n      <th>f91</th>\n      <th>f92</th>\n      <th>f93</th>\n      <th>f94</th>\n      <th>f95</th>\n      <th>f96</th>\n      <th>f97</th>\n      <th>f98</th>\n      <th>f99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>...</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.511213</td>\n      <td>51.378476</td>\n      <td>0.107155</td>\n      <td>0.050010</td>\n      <td>3595.133426</td>\n      <td>8.205953</td>\n      <td>164.508753</td>\n      <td>0.375533</td>\n      <td>16.669745</td>\n      <td>1.190382</td>\n      <td>...</td>\n      <td>0.581002</td>\n      <td>4856.812768</td>\n      <td>22.579100</td>\n      <td>2.030554</td>\n      <td>0.079692</td>\n      <td>1.555097</td>\n      <td>2.417556</td>\n      <td>0.537484</td>\n      <td>1.576900</td>\n      <td>8.048805</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.307884</td>\n      <td>42.396636</td>\n      <td>1.322200</td>\n      <td>0.792368</td>\n      <td>6072.401061</td>\n      <td>5.475723</td>\n      <td>183.335563</td>\n      <td>0.813597</td>\n      <td>99.758709</td>\n      <td>0.099700</td>\n      <td>...</td>\n      <td>0.445022</td>\n      <td>8501.609009</td>\n      <td>14.849390</td>\n      <td>0.900211</td>\n      <td>0.587780</td>\n      <td>9.253785</td>\n      <td>0.892563</td>\n      <td>0.226589</td>\n      <td>0.646306</td>\n      <td>5.647368</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-0.069273</td>\n      <td>-17.000000</td>\n      <td>-7.895580</td>\n      <td>-1.475560</td>\n      <td>-7589.280000</td>\n      <td>-3.291050</td>\n      <td>-40.967200</td>\n      <td>-4.143080</td>\n      <td>-502.813000</td>\n      <td>0.934037</td>\n      <td>...</td>\n      <td>-0.379189</td>\n      <td>-12695.700000</td>\n      <td>-4.059170</td>\n      <td>0.057800</td>\n      <td>-1.998800</td>\n      <td>-24.686300</td>\n      <td>-1.131980</td>\n      <td>0.005249</td>\n      <td>-0.646967</td>\n      <td>-0.842397</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.251287</td>\n      <td>18.000000</td>\n      <td>-0.611172</td>\n      <td>-0.719418</td>\n      <td>163.864750</td>\n      <td>4.110127</td>\n      <td>27.894900</td>\n      <td>-0.026245</td>\n      <td>-17.392025</td>\n      <td>1.132640</td>\n      <td>...</td>\n      <td>0.280511</td>\n      <td>73.203100</td>\n      <td>11.525450</td>\n      <td>1.471650</td>\n      <td>-0.408975</td>\n      <td>-4.004925</td>\n      <td>1.906718</td>\n      <td>0.359646</td>\n      <td>1.215810</td>\n      <td>3.732800</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.514962</td>\n      <td>41.000000</td>\n      <td>0.253815</td>\n      <td>0.004099</td>\n      <td>943.000500</td>\n      <td>7.472445</td>\n      <td>91.005250</td>\n      <td>0.619862</td>\n      <td>8.714945</td>\n      <td>1.170370</td>\n      <td>...</td>\n      <td>0.480568</td>\n      <td>1060.025000</td>\n      <td>19.993200</td>\n      <td>1.660830</td>\n      <td>0.215710</td>\n      <td>0.759942</td>\n      <td>2.340430</td>\n      <td>0.531347</td>\n      <td>1.451285</td>\n      <td>7.182205</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.777323</td>\n      <td>75.000000</td>\n      <td>0.759249</td>\n      <td>0.765456</td>\n      <td>4115.355000</td>\n      <td>11.030950</td>\n      <td>240.843750</td>\n      <td>0.933855</td>\n      <td>55.407625</td>\n      <td>1.218880</td>\n      <td>...</td>\n      <td>0.766532</td>\n      <td>5572.982500</td>\n      <td>32.271625</td>\n      <td>2.320085</td>\n      <td>0.503134</td>\n      <td>6.202502</td>\n      <td>2.910020</td>\n      <td>0.709807</td>\n      <td>1.901633</td>\n      <td>10.998550</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.072070</td>\n      <td>273.000000</td>\n      <td>9.768590</td>\n      <td>1.680190</td>\n      <td>37847.500000</td>\n      <td>35.078000</td>\n      <td>947.143000</td>\n      <td>4.010380</td>\n      <td>465.956000</td>\n      <td>1.712450</td>\n      <td>...</td>\n      <td>3.422660</td>\n      <td>54334.600000</td>\n      <td>79.912400</td>\n      <td>5.403020</td>\n      <td>1.944190</td>\n      <td>42.890400</td>\n      <td>5.576040</td>\n      <td>1.105400</td>\n      <td>4.492620</td>\n      <td>34.019200</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 100 columns</p>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "X_train[X_train.columns] = X_train[X_train.columns].apply(lambda x: ((x - x.min()) / (x.max() - x.min())))\n",
    "test_data[test_data.columns] = test_data[test_data.columns].apply(lambda x: ((x - x.min()) / (x.max() - x.min())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,785\n",
      "Trainable params: 6,657\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "        layers.Input(shape = (100,)),\n",
    "        #layers.Embedding(400, 8, embeddings_regularizer='l2', input_length=75),\n",
    "        #layers.Conv1D(32, 3, activation='relu', padding='same', input_shape=(100,1)),\n",
    "        #layers.Flatten(),\n",
    "        #layers.Dropout(0.2),\n",
    "        #layers.LayerNormalization(),\n",
    "        layers.Dense(units = 64, activation ='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation = 'relu'),\n",
    "    ])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "X_train_split, X_val_split, Y_train_split, Y_val_split = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 100, stratify = Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"root_mean_squared_error\",\n",
    "    patience=20,\n",
    "    min_delta=0.0001,\n",
    "    restore_best_weights=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#model.compile(loss='mse', optimizer = keras.optimizers.Adam(learning_rate=0.0005),  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "#history = model.fit(X_train_split, Y_train_split,\n",
    "#          batch_size = 256, epochs = 100,\n",
    "#          validation_data=(X_val_split, Y_val_split),\n",
    "#          callbacks=[early_stopping,tensorboard_callback],\n",
    "#           )\n",
    "#score = model.evaluate(X_val_split, Y_val_split, verbose = 0)\n",
    "#print('Test loss: {}'.format(score[0]))\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kfold.split(X_train, Y_train):\n",
    "    model.compile(loss='mse', optimizer = keras.optimizers.Adam(learning_rate=0.05), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    history = model.fit(X_train.iloc[train_index], Y_train.iloc[train_index],\n",
    "          batch_size = 256, epochs = 100,\n",
    "          validation_data=(X_train.iloc[test_index], Y_train.iloc[test_index]),\n",
    "          callbacks=[early_stopping,tensorboard_callback],\n",
    "           )\n",
    "    score = model.evaluate(X_train.iloc[test_index], Y_train.iloc[test_index], verbose = 0)\n",
    "    print('Test loss: {}'.format(score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:9.93379\n",
      "[1]\tvalidation_0-rmse:9.75356\n",
      "[2]\tvalidation_0-rmse:9.58825\n",
      "[3]\tvalidation_0-rmse:9.43663\n",
      "[4]\tvalidation_0-rmse:9.29755\n",
      "[5]\tvalidation_0-rmse:9.17005\n",
      "[6]\tvalidation_0-rmse:9.05340\n",
      "[7]\tvalidation_0-rmse:8.94676\n",
      "[8]\tvalidation_0-rmse:8.84938\n",
      "[9]\tvalidation_0-rmse:8.76065\n",
      "[10]\tvalidation_0-rmse:8.67948\n",
      "[11]\tvalidation_0-rmse:8.60573\n",
      "[12]\tvalidation_0-rmse:8.53848\n",
      "[13]\tvalidation_0-rmse:8.47707\n",
      "[14]\tvalidation_0-rmse:8.42134\n",
      "[15]\tvalidation_0-rmse:8.37044\n",
      "[16]\tvalidation_0-rmse:8.32444\n",
      "[17]\tvalidation_0-rmse:8.28269\n",
      "[18]\tvalidation_0-rmse:8.24446\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "for train_index, test_index in kfold.split(X_train, Y_train):\n",
    "    model = XGBRegressor(n_estimators=500, learning_rate=0.05, n_jobs=4)\n",
    "    model.fit(X_train.iloc[train_index], Y_train.iloc[train_index],\n",
    "                 early_stopping_rounds=5,\n",
    "                 eval_set=[(X_train.iloc[test_index], Y_train.iloc[test_index])],\n",
    "                 verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data[test_data.columns] = test_data[test_data.columns].apply(lambda x: ((x - x.min()) / (x.max() - x.min())))\n",
    "predicts = model.predict(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output = pd.DataFrame(predicts, columns = ['loss'])\n",
    "output['id'] = test_data.index\n",
    "output.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}